# Logging on GCP 

## 1.-You are asked to create a strategy that allows you to move the log events generated by your applications in Google Cloud so that the analytics team can execute queries in BigQuery. Which type of strategy is the most appropriate to move data from Cloud Logging to BigQuery? 

- a) Configure BigQuery to obtain the data from Cloud Logging. 
- b) **Create a data sink toward BigQuery.**
- c) Create a batch process that moves data from Cloud Logging to BigQuery overnight. 
- d) Create an event-oriented architecture that allows data to be moved from Cloud Logging to BigQuery. 

YOUTUBE: https://www.youtube.com/watch?v=s8w426fwNIo


## 2.-You have just implemented a log for your application but are having difficulty filtering the different events. Which strategy would you use to solve the problem? 

- a) Create a dashboard to view the logs.
- b) Save the logs in a relational database. 
- c) Register logs in different projects. 
- d) **Register logs at the different levels available.**

## 3.-You have a microservices architecture mounted on Google Cloud but you are having difficulties when troubleshooting and following the traceability of your logs. Which modification would you make in the structure of your logs to simplify the troubleshooting activity? 

- a) Add a description to the logs. 
- b) Add a unique ID to each event. 
- c) **Register the logs at different levels.**
- d) Save the logs in a database. 

## 4.-You are realizing that you are saving many logs that are not necessary for the operation and this is increasing costs considerably. Which modification would you make to reduce the number of logs and operating costs? 

- a) **Move logs to BigQuery.**
- b) Save log partitions in different Cloud Storage buckets. 
- c) Exclude logs that have a 200 OK status code. 
- d) Migrate the logs to a NoSQL database. 

## 5.-How is it possible to centralize the logs of multiple applications in an organization in a single project? 

- a) **By creating an organization-level sink that stores the logs in a log bucket**
- b) By having a batch process that moves the Cloud Logging data to a centralized project every night 
- c) By duplicating application instances in a centralized project to record logs in multiple projects
- d) By creating a filter to save logs in multiple projects


[Aggregate and store your organization's logs](https://cloud.google.com/logging/docs/central-log-storage)

    This process involves the following steps:
    - Creating the Cloud Logging bucket for storing the aggregated logs.
    - Creating the sink at the organization level to route the logs to the new bucket.
    - Configuring read access to the new bucket.
    - Searching logs from the Logs Explorer page.